Number of images to test: 10000 , to train: 60000, first image size:=28  28  28, var=1576.9047142047, min=0.000000, max=255.000000
    <strong>trainLoopCount</strong><strong>    testImageNum</strong><strong>    ni_initial</strong><strong>    ni_final</strong><strong>    noImprovementTh</strong><strong>    momentum</strong><strong>    constInitWeight</strong><strong>    lambda</strong><strong>    errorMethod</strong><strong>    testOnData</strong><strong>    addBackround</strong><strong>    testOnNull</strong><strong>    augmentImage</strong><strong>    augmentParams</strong><strong>    centralizeImage</strong><strong>    cropImage</strong><strong>    flipImage</strong><strong>    useRandomPatch</strong><strong>    testNumPatches</strong><strong>    selevtivePatchVarTh</strong><strong>    testOnMiddlePatchOnly</strong><strong>    normalizeNetworkInput</strong><strong>     sizeFmInput  </strong><strong>    numFmInput</strong>
    <strong>______________</strong>    <strong>____________</strong>    <strong>__________</strong>    <strong>________</strong>    <strong>_______________</strong>    <strong>________</strong>    <strong>_______________</strong>    <strong>______</strong>    <strong>___________</strong>    <strong>__________</strong>    <strong>____________</strong>    <strong>__________</strong>    <strong>____________</strong>    <strong>_____________</strong>    <strong>_______________</strong>    <strong>_________</strong>    <strong>_________</strong>    <strong>______________</strong>    <strong>______________</strong>    <strong>___________________</strong>    <strong>_____________________</strong>    <strong>_____________________</strong>    <strong>______________</strong>    <strong>__________</strong>

    500               1000            0.05          1e-05       50                 0           NaN                0         1              0             0               0             0               [1x1 struct]     0                  0            0            0                 1                 0                      0                        1                        28    28    28    1         

    <strong>storeMaxMSENet</strong><strong>    verifyBP</strong><strong>    displayConvNet</strong><strong>    iter</strong><strong>    imagesLearned</strong><strong>    maxsucessRate</strong><strong>    noImprovementCount</strong><strong>    minMSE</strong><strong>    improvementRefMSE</strong><strong>      endSeed   </strong><strong>    datasetInfo </strong>
    <strong>______________</strong>    <strong>________</strong>    <strong>______________</strong>    <strong>____</strong>    <strong>_____________</strong>    <strong>_____________</strong>    <strong>__________________</strong>    <strong>______</strong>    <strong>_________________</strong>    <strong>____________</strong>    <strong>____________</strong>

    0                 1           0                 0       0                0                0                     Inf       Inf                  [1x1 struct]    [1x1 struct]

Layer 1: Activation=Relu, dActivation=dRelu
    <strong>type</strong><strong>    numFm</strong><strong>         Activation      </strong><strong>         dActivation     </strong><strong>      kernel   </strong><strong>        pad    </strong><strong>      stride   </strong><strong>      pooling  </strong><strong>    numFmInPrevLayer</strong><strong>    sizeFmInPrevLayer</strong><strong>    dropOut</strong><strong>    inputDim</strong><strong>         out      </strong><strong>    numWeights</strong><strong>                    indexesStride                 </strong>
    <strong>____</strong>    <strong>_____</strong>    <strong>_____________________</strong>    <strong>_____________________</strong>    <strong>___________</strong>    <strong>___________</strong>    <strong>___________</strong>    <strong>___________</strong>    <strong>________________</strong>    <strong>_________________</strong>    <strong>_______</strong>    <strong>________</strong>    <strong>______________</strong>    <strong>__________</strong>    <strong>______________________________________________</strong>

    2       7        [1x1 function_handle]    [1x1 function_handle]    5    5    5    2    2    2    2    2    4    1    1    1    1                   28    28    28       1          3           14    14     7    882           [1x14 double]    [1x14 double]    [1x7 double]

Layer 2: Activation=Sigmoid, dActivation=dSigmoid
    <strong>type</strong><strong>    numFm</strong><strong>      kernel   </strong><strong>        pad    </strong><strong>      pooling  </strong><strong>    numFmInPrevLayer</strong><strong>    sizeFmInPrevLayer</strong><strong>    dropOut</strong><strong>         Activation      </strong><strong>         dActivation     </strong><strong>    inputDim</strong><strong>      stride   </strong><strong>         out      </strong><strong>    numWeights</strong><strong>                    indexesStride                 </strong>
    <strong>____</strong>    <strong>_____</strong>    <strong>___________</strong>    <strong>___________</strong>    <strong>___________</strong>    <strong>________________</strong>    <strong>_________________</strong>    <strong>_______</strong>    <strong>_____________________</strong>    <strong>_____________________</strong>    <strong>________</strong>    <strong>___________</strong>    <strong>______________</strong>    <strong>__________</strong>    <strong>______________________________________________</strong>

    2       17       5    5    3    1    1    0    1    1    1    7                   14    14     7       1          [1x1 function_handle]    [1x1 function_handle]    3           1    1    1    12    12     5    8942          [1x12 double]    [1x12 double]    [1x5 double]

Layer 3: Activation=Sigmoid, dActivation=dSigmoid
    <strong>type</strong><strong>    numFm</strong><strong>    numFmInPrevLayer</strong><strong>    sizeFmInPrevLayer</strong><strong>    dropOut</strong><strong>         Activation      </strong><strong>         dActivation     </strong><strong>    out</strong><strong>    numWeights</strong>
    <strong>____</strong>    <strong>_____</strong>    <strong>________________</strong>    <strong>_________________</strong>    <strong>_______</strong>    <strong>_____________________</strong>    <strong>_____________________</strong>    <strong>___</strong>    <strong>__________</strong>

    1       128      17                  12    12     5       1          [1x1 function_handle]    [1x1 function_handle]    1      1.5668e+06

Layer 4: Activation=Sigmoid, dActivation=dSigmoid
    <strong>type</strong><strong>    numFm</strong><strong>    numFmInPrevLayer</strong><strong>    sizeFmInPrevLayer</strong><strong>    dropOut</strong><strong>         Activation      </strong><strong>         dActivation     </strong><strong>    out</strong><strong>    numWeights</strong>
    <strong>____</strong>    <strong>_____</strong>    <strong>________________</strong>    <strong>_________________</strong>    <strong>_______</strong>    <strong>_____________________</strong>    <strong>_____________________</strong>    <strong>___</strong>    <strong>__________</strong>

    1       10       128                 1                    1          [1x1 function_handle]    [1x1 function_handle]    1      1290      

Network properties:

    <strong>numLayers</strong><strong>    numOutputs</strong><strong>    version</strong><strong>      sources   </strong><strong>    numWeights</strong><strong>      sizeInput   </strong><strong>    InputNumFm</strong>
    <strong>_________</strong>    <strong>__________</strong>    <strong>_______</strong>    <strong>____________</strong>    <strong>__________</strong>    <strong>______________</strong>    <strong>__________</strong>

    4            10            1.1        [3x1 struct]    1.578e+06     28    28    28    1         

Verifying backProp..Network is OK. Verification time=28.12
Start training iterations
Iter 1  | Imgs=500  | time=113.18 | TrainErr=0.155506 | meanGrad=0.016170 | meanWeight=0.008197 | varWeight=0.000141 | MSE=1.707818 | scesRate=68.90% | minMSE=1.707818 | maxS=68.90% | ni=0.050000 | tstTime=45.81 | totalTime=159.01 | noImpCnt=0/50
Iter 2  | Imgs=1000 | time=113.63 | TrainErr=0.071217 | meanGrad=0.028314 | meanWeight=0.009173 | varWeight=0.000195 | MSE=1.269657 | scesRate=74.60% | minMSE=1.269657 | maxS=74.60% | ni=0.050000 | tstTime=46.58 | totalTime=319.90 | noImpCnt=0/50
Iter 3  | Imgs=1500 | time=115.18 | TrainErr=0.054076 | meanGrad=0.029894 | meanWeight=0.010006 | varWeight=0.000242 | MSE=0.677720 | scesRate=88.70% | minMSE=0.677720 | maxS=88.70% | ni=0.050000 | tstTime=46.40 | totalTime=482.13 | noImpCnt=0/50
Iter 4  | Imgs=2000 | time=114.35 | TrainErr=0.030681 | meanGrad=0.019926 | meanWeight=0.010469 | varWeight=0.000273 | MSE=0.545333 | scesRate=90.40% | minMSE=0.545333 | maxS=90.40% | ni=0.050000 | tstTime=45.89 | totalTime=643.05 | noImpCnt=0/50
Iter 5  | Imgs=2500 | time=113.22 | TrainErr=0.026893 | meanGrad=0.020818 | meanWeight=0.010927 | varWeight=0.000303 | MSE=0.643100 | scesRate=87.60% | minMSE=0.545333 | maxS=90.40% | ni=0.050000 | tstTime=45.84 | totalTime=802.76 | noImpCnt=0/50
Iter 6  | Imgs=3000 | time=113.13 | TrainErr=0.025806 | meanGrad=0.021845 | meanWeight=0.011379 | varWeight=0.000334 | MSE=0.518508 | scesRate=91.60% | minMSE=0.518508 | maxS=91.60% | ni=0.050000 | tstTime=45.90 | totalTime=962.46 | noImpCnt=1/50
Iter 7  | Imgs=3500 | time=113.21 | TrainErr=0.022748 | meanGrad=0.021606 | meanWeight=0.011765 | varWeight=0.000363 | MSE=0.577361 | scesRate=90.70% | minMSE=0.518508 | maxS=91.60% | ni=0.050000 | tstTime=46.22 | totalTime=1122.51 | noImpCnt=0/50
Iter 8  | Imgs=4000 | time=116.41 | TrainErr=0.023507 | meanGrad=0.021189 | meanWeight=0.012158 | varWeight=0.000391 | MSE=0.399342 | scesRate=93.40% | minMSE=0.399342 | maxS=93.40% | ni=0.050000 | tstTime=46.44 | totalTime=1286.00 | noImpCnt=1/50
Iter 9  | Imgs=4500 | time=114.44 | TrainErr=0.022161 | meanGrad=0.020063 | meanWeight=0.012574 | varWeight=0.000420 | MSE=0.441868 | scesRate=92.10% | minMSE=0.399342 | maxS=93.40% | ni=0.050000 | tstTime=45.78 | totalTime=1446.90 | noImpCnt=0/50
Iter 10 | Imgs=5000 | time=113.07 | TrainErr=0.022152 | meanGrad=0.018926 | meanWeight=0.012934 | varWeight=0.000446 | MSE=0.375902 | scesRate=93.10% | minMSE=0.375902 | maxS=93.40% | ni=0.050000 | tstTime=46.00 | totalTime=1606.62 | noImpCnt=1/50
Iter 11 | Imgs=5500 | time=115.81 | TrainErr=0.018449 | meanGrad=0.017266 | meanWeight=0.013239 | varWeight=0.000471 | MSE=0.301109 | scesRate=94.80% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=46.35 | totalTime=1769.43 | noImpCnt=0/50
Iter 12 | Imgs=6000 | time=116.44 | TrainErr=0.020461 | meanGrad=0.017543 | meanWeight=0.013559 | varWeight=0.000496 | MSE=0.358510 | scesRate=93.40% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=46.42 | totalTime=1932.97 | noImpCnt=0/50
Iter 13 | Imgs=6500 | time=115.12 | TrainErr=0.015037 | meanGrad=0.014203 | meanWeight=0.013787 | varWeight=0.000514 | MSE=0.393111 | scesRate=93.20% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=47.17 | totalTime=2095.92 | noImpCnt=1/50
Iter 14 | Imgs=7000 | time=115.23 | TrainErr=0.019960 | meanGrad=0.020288 | meanWeight=0.014073 | varWeight=0.000538 | MSE=0.358982 | scesRate=93.20% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=46.48 | totalTime=2258.32 | noImpCnt=2/50
Iter 15 | Imgs=7500 | time=115.36 | TrainErr=0.021789 | meanGrad=0.021396 | meanWeight=0.014395 | varWeight=0.000564 | MSE=0.389280 | scesRate=92.80% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=45.81 | totalTime=2420.16 | noImpCnt=3/50
Iter 16 | Imgs=8000 | time=113.35 | TrainErr=0.019286 | meanGrad=0.018054 | meanWeight=0.014684 | varWeight=0.000589 | MSE=0.505239 | scesRate=91.00% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=45.82 | totalTime=2579.98 | noImpCnt=4/50
Iter 17 | Imgs=8500 | time=113.53 | TrainErr=0.020172 | meanGrad=0.018586 | meanWeight=0.014958 | varWeight=0.000612 | MSE=0.370682 | scesRate=93.70% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=46.36 | totalTime=2740.53 | noImpCnt=5/50
Iter 18 | Imgs=9000 | time=116.04 | TrainErr=0.024647 | meanGrad=0.024447 | meanWeight=0.015276 | varWeight=0.000641 | MSE=0.316905 | scesRate=94.80% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=46.56 | totalTime=2903.79 | noImpCnt=6/50
Iter 19 | Imgs=9500 | time=116.55 | TrainErr=0.017074 | meanGrad=0.018318 | meanWeight=0.015502 | varWeight=0.000664 | MSE=0.386508 | scesRate=94.30% | minMSE=0.301109 | maxS=94.80% | ni=0.050000 | tstTime=46.45 | totalTime=3067.45 | noImpCnt=7/50
Iter 20 | Imgs=10000 | time=115.21 | TrainErr=0.011232 | meanGrad=0.011497 | meanWeight=0.015653 | varWeight=0.000680 | MSE=0.267906 | scesRate=96.00% | minMSE=0.267906 | maxS=96.00% | ni=0.050000 | tstTime=46.42 | totalTime=3229.74 | noImpCnt=8/50
Iter 21 | Imgs=10500 | time=114.97 | TrainErr=0.016866 | meanGrad=0.017909 | meanWeight=0.015883 | varWeight=0.000702 | MSE=0.234427 | scesRate=96.30% | minMSE=0.234427 | maxS=96.30% | ni=0.050000 | tstTime=46.31 | totalTime=3391.67 | noImpCnt=0/50
Iter 22 | Imgs=11000 | time=115.16 | TrainErr=0.011765 | meanGrad=0.014335 | meanWeight=0.016077 | varWeight=0.000720 | MSE=0.399516 | scesRate=93.50% | minMSE=0.234427 | maxS=96.30% | ni=0.050000 | tstTime=46.31 | totalTime=3553.82 | noImpCnt=0/50
Iter 23 | Imgs=11500 | time=117.61 | TrainErr=0.013016 | meanGrad=0.016334 | meanWeight=0.016250 | varWeight=0.000739 | MSE=0.273253 | scesRate=94.70% | minMSE=0.234427 | maxS=96.30% | ni=0.050000 | tstTime=47.19 | totalTime=3719.32 | noImpCnt=1/50
Iter 24 | Imgs=12000 | time=115.82 | TrainErr=0.016435 | meanGrad=0.021908 | meanWeight=0.016479 | varWeight=0.000763 | MSE=0.280933 | scesRate=95.30% | minMSE=0.234427 | maxS=96.30% | ni=0.050000 | tstTime=46.43 | totalTime=3882.33 | noImpCnt=2/50
Iter 25 | Imgs=12500 | time=116.47 | TrainErr=0.012566 | meanGrad=0.015760 | meanWeight=0.016658 | varWeight=0.000783 | MSE=0.256209 | scesRate=95.60% | minMSE=0.234427 | maxS=96.30% | ni=0.050000 | tstTime=46.40 | totalTime=4045.86 | noImpCnt=3/50
Iter 26 | Imgs=13000 | time=116.40 | TrainErr=0.016214 | meanGrad=0.019025 | meanWeight=0.016915 | varWeight=0.000809 | MSE=0.286854 | scesRate=95.40% | minMSE=0.234427 | maxS=96.30% | ni=0.050000 | tstTime=46.40 | totalTime=4209.34 | noImpCnt=4/50
Iter 27 | Imgs=13500 | time=116.50 | TrainErr=0.017181 | meanGrad=0.020534 | meanWeight=0.017205 | varWeight=0.000839 | MSE=0.250208 | scesRate=95.90% | minMSE=0.234427 | maxS=96.30% | ni=0.050000 | tstTime=46.33 | totalTime=4372.85 | noImpCnt=5/50
Iter 28 | Imgs=14000 | time=116.50 | TrainErr=0.013456 | meanGrad=0.016857 | meanWeight=0.017414 | varWeight=0.000860 | MSE=0.268228 | scesRate=95.80% | minMSE=0.234427 | maxS=96.30% | ni=0.050000 | tstTime=46.33 | totalTime=4536.34 | noImpCnt=6/50
Iter 29 | Imgs=14500 | time=115.06 | TrainErr=0.016310 | meanGrad=0.018689 | meanWeight=0.017639 | varWeight=0.000884 | MSE=0.233042 | scesRate=95.80% | minMSE=0.233042 | maxS=96.30% | ni=0.050000 | tstTime=46.43 | totalTime=4698.50 | noImpCnt=7/50
Iter 30 | Imgs=15000 | time=115.42 | TrainErr=0.015067 | meanGrad=0.020446 | meanWeight=0.017865 | varWeight=0.000907 | MSE=0.214984 | scesRate=96.30% | minMSE=0.214984 | maxS=96.30% | ni=0.050000 | tstTime=46.40 | totalTime=4860.98 | noImpCnt=0/50
Finish training. max images reached
